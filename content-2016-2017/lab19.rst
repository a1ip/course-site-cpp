Параллельные сортировки 
#######################

:date: 2017-03-09 09:00


.. default-role:: code
.. contents:: Содержание


Постановка задачи
=================

Задача расстановки фрагментов данных в правильном порядке настолько популярна и настолько богата эффектами, что Д.Э. Кнут посвятил ей половину третьего тома своей трилогии "Искусство программирования для ЭВМ". Распараллеливание этой задачи не менее интересно. 

Итак, требуется расположить в порядке неубывания n элементов массива чисел, равномерно
размещенных на p процессорах. По окончании сортировки на процессорах с меньшими
номерами должны быть размещены элементы массива с меньшими значениями(сортировка типа all-to-all) или же они все должны быть собраны в одном массиве на одном узле в правильном порядке(типа all-to-one).
 
Действие почти всех схем сортировки, подразумевающих распараллеливание, происходит в несколько этапов : 

* последовательная сортировка фрагментов массива, распределенных по процессорам(узлам) системы;
* объединение(слияние) упорядоченных фрагментов массива – перемещение элементов массива между узлами с целью согласования их порядка (чтоб весь большой массив в-общем был упорядочен).

Для уменьшения общего времени выполнения сортировки следует по
возможности сократить время выполнения каждого из указанных этапов, поэтому в
начале обсуждается последовательный алгоритм, показавший наименьшее время
сортировки тестовых массивов. Именно относительно этого алгоритма определяется
эффективность алгоритмов параллельной сортировки. Таким образом, в работе
используется метод определения эффективности относительно «наилучшего» из
имеющихся в распоряжении последовательных алгоритмов сортировки.


Параллельные алгоритмы сортировки
=================================



	

Рассмотрим два параллельных алгоритма сортировки массивов. Первый
разработан на основе метода сдваивания - после сортировки своего фрагмента на каждом узле - фрагменты массивов попарно сливаются , второй - на основе «обменной сортировки со
слиянием» Бэтчера.


Их описание и некоторые результаты по их эффективности на разных массивах чисел см. в следующей статье__.

.. __: {filename}/extra/ParallelSort.pdf

(см. стр. 9-16)


All-to-one
===========

В этой лабораторной работе рассматриваются так называемые методы сортировки all2one (все-к-одному) - то есть когда фрагменты массива сначала сортируются на разных узлах, а затем собираются вместе на один узел (как правило с номером 0). Как нетрудно догадаться, эффективность такого рода методов напрямую зависит от правильного слияния упорядоченных фрагментов в один массив. Иначе выигрыш в производительности за счёт распараллеливания будет с треском теряться за счёт неудачных взаимодействий. 

Итак, представим, что нам надо соединить вместе n массивов чисел и пусть на каждом шаге мы можем соединять вместе любые 2 из них. И , кроме того, если пары узлов не пересекаются, то соединять их массивы можно независимо друг от друга, а, значит, одновременно. 
Как это сделать быстрее всего? 
Очевидно, для этого нужно, чтоб на каждом этапе сливались вместе максимальное число пар фрагментов. 
Всего из n фрагментов можно составить максимум [n/2] непересекающихся пар ([] означают целую часть числа в скобках). Значит, на каждом шаге i, если осталось n(i) неслитых фрагментов, то  нужно сливать вместе [n(i)] их пар - подобно складыванию простыни. Как этого добиться? 
Как видно из следующей картинки.

.. image:: {filename}/images/lab19/dhscheme.png
   :width: 800 px
   :align: center


Как нетрудно видеть, на k-м шаге фрагмент с номером s сравнивается с процессом с номером r=s(mod 2^k) (r и s дают при делении на 2^k - k-ю степень числа 2 одинаковый остаток). Именно поэтому данная схема слияния (оптимальная по числу шагов) называется гиперкубом. Если построить гиперкуб размерности k=[log2(n)], где n - число узлов, то на кажджом шаге нужно снижать размерность гиперкуба на 1, сливая фрагменты в узлах со стоящими в узлах напротив по соответствующей размерности. 
   
.. image:: {filename}/images/lab19/cube.png
   :width: 400 px
   :align: center

См. на рисунке схема слияния для не более , чем 2^3=8 узлов. В вершинах куба двоичный код номера узла. 

Прежде, чем перейти к заданию, можно рекомендовать подробнее ознакомиться с процедурами пересылки сообщений в mpi. Например, здесь__

.. __: {filename}/extra/P2P.pdf

Задание 1 (сортировка бинарным слиянием)
========================================

На этом занятии предлагается Реализовать алгоритм сдваивания, вычислить время работы на 4,16,28 процессах. Сравнить с qsort на разных входах.

В папке /tmp/54x/mpi_merge_sort есть заготовка - файл mpi_merge_sort_task.c__

.. __: {filename}/extra/mpi_merge_sort_task.c
	 
В нём уже реализованы генерация случайных чисел, их распределение по процессам. Необходимо дописать сортировку слиянием и схему слияния массивов на разных узлах. 

Для проверки
 
#. Cкопировать себе в рабочую папку полностью папку /tmp/54x/mpi_merge_sort со всем содержимым
#. Не изменять имени файла mpi_merge_sort_task.c - когда допишете недостающее 
#. Запустить скрипт check.sh
#. Следить за увлекательным процессом проверки 

Задание 2 (альтернативное - суммирование по схеме "гиперкуб")
==============================================================

Если сложно с сортировкой - попробуйте написать аналог процедуры MPI_Reduce(...,MPI_SUM,...); с помощью той же схемы бинарного слияния. В папке /tmp/54x/sum_hypercube лежит заготовка sum_hypercube.c программы, реализующей  суммирование номеров процессов - как MPI_Reduce(&rank,...,MPI_SUM,...) . Нужно дописать функцию sum_hypercube(int x). Тестировать точно так же, через bash-скрипты, как сказано выше (предварительно скопировав себе check.sh и библиотеку roundup). 
Файл-исходник с вашим решением должен называться так же, sum_hypercube.c





